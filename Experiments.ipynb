{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "This Bash notebook can be used to run notebook-based experiments, locally or on cloud infrastructure: notebooks are run as scripts by papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export NOTEBOOK_NAME=\"02-Randomized-Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export CMD_LOCAL=\"papermill $NOTEBOOK_NAME.ipynb output/$NOTEBOOK_NAME.ipynb\"\n",
    "export CMD_CLOUD_LOCAL=\"papermill $NOTEBOOK_NAME.ipynb /artifacts/$NOTEBOOK_NAME.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with local Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash -c \"$CMD_LOCAL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment on Cloud\n",
    "\n",
    "Using Gradient Jobs / Experiments with the following options:\n",
    "\n",
    "* `--name` gives the name of the job/experiment\n",
    "* `--machineType`: see Gradient's [instance types](https://docs.paperspace.com/gradient/instances/instance-types)\n",
    "* `--experimentEnv` (or `--jobEnv` for jobs) allows to specify [environment variables](https://docs.paperspace.com/gradient/experiments/using-experiments/environment-variables); here we define `DATA_PATH`, which will be used by our data loading utils ([mlxtend.utils.data](https://github.com/louisdorard/mlxtend/tree/master/mlxtend/utils/data.py)) to find data files\n",
    "* `--workspace`: setting it to the current directory (`./`) will upload the contents of this directory to the instance used for this job/experiment, at `/paperspace/`; an alternative is to use [`--workspaceRef`](https://docs.paperspace.com/gradient/experiments/using-experiments/git-commit-tracking#example)\n",
    "* `--command`: this is executed from `/paperspace/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MACHINE_TYPE=C3 # C3 has 2 cores, C7 has 12 cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient jobs create \\\n",
    "#   --name $NOTEBOOK_NAME \\\n",
    "#   --machineType $MACHINE_TYPE \\\n",
    "#   --container louisdorard/full-stack-ml \\\n",
    "#   --command \"bash -c '$CMD_CLOUD_LOCAL'\" \\\n",
    "#   --workspace ./ \\\n",
    "#   --jobEnv \"{\\\"DATA_PATH\\\":\\\"/storage/data/\\\"}\" \\\n",
    "#   --projectId $GRADIENT_PROJECT_ID\n",
    "# TODO: grep jobID and save it to file, so we can read it when downloading artifacts below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient experiments run singlenode \\\n",
    "   --name $NOTEBOOK_NAME \\\n",
    "   --machineType $MACHINE_TYPE \\\n",
    "   --container louisdorard/full-stack-ml \\\n",
    "   --command \"bash -c '$CMD_CLOUD_LOCAL'\" \\\n",
    "   --workspace ./ \\\n",
    "   --experimentEnv \"{\\\"DATA_PATH\\\":\\\"/storage/data/\\\"}\" \\\n",
    "   --projectId $GRADIENT_PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show list of jobs in our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient jobs list --projectId $GRADIENT_PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ours in this list, based on the date/time. Get corresponding job ID and use below, so we can download the output notebook from the job's artifacts, and move it to `output/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient jobs artifacts download \\\n",
    "--jobId XXX \\\n",
    "--destinationDir output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it's also possible to use `experiments run` instead of `jobs create`...\n",
    "\n",
    "* `experiments run` is blocking; it streams logs to the output of the command; it seems to handle environment variables more reliably; can we download experiment artifacts afterwards?\n",
    "* `jobs create` is non-blocking; it allows to download job artifacts; does it take environment variables into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you didn't already have the data in this team storage associated to this project, download it by adding your Kaggle username and Key in the environment variables listed below, and executing:\n",
    "\n",
    "```bash\n",
    "gradient experiments run singlenode \\\n",
    "   --name download \\\n",
    "   --machineType C3 \\\n",
    "   --container louisdorard/full-stack-ml \\\n",
    "   --command \"mkdir /storage/data/; bash setup/scripts/Download-Data.sh\" \\\n",
    "   --workspace https://github.com/louisdorard/full-stack-ml.git \\\n",
    "   --experimentEnv \"{\\\"DATA_PATH\\\":\\\"/storage/data/\\\", \\\"KAGGLE_USERNAME\\\":\\\"louisdorard\\\", \\\"KAGGLE_KEY\\\":\\\"173c540463db94622281ce949e1dff07\\\"}\" \\\n",
    "   --projectId $GRADIENT_PROJECT_ID\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Gradient documentation](https://docs.paperspace.com/gradient/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in Process: turn this into bash script\n",
    "\n",
    "`NOTEBOOK_NAME` and `EXEC_MODE` would be arguments of this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case $EXEC_MODE in\n",
    "    docker) CMD=$CMD_DOCKER\n",
    "    cloud) CMD=...\n",
    "    *) CMD=$CMD_LOCAL\n",
    "esac"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,scripts//sh"
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
